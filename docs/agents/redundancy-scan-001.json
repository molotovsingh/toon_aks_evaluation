{
  "agent_id": "redundancy-scan-001",
  "name": "Redundant Code Scanner",
  "version": "1.0",
  "description": "Scans the repository for redundant code (exact/near duplicates and unused definitions) and produces a structured report.",

  "run_policy": {
    "read_only": true,
    "allow_network": false,
    "mutation_allowed": false,
    "respect_agents_md": true
  },

  "scope": {
    "include_paths": [
      "src/",
      "app.py",
      "scripts/",
      "examples/",
      "tests/"
    ],
    "exclude_paths": [
      "output/",
      ".venv/",
      ".git/",
      "docs/",
      "benchmark_results/",
      "streamlit_outputs/",
      "temp_files/"
    ],
    "file_globs": [
      "**/*.py"
    ],
    "max_files": 2000,
    "max_file_size_kb": 512
  },

  "task": {
    "objective": "Check for redundant code and report back.",
    "outputs": {
      "report_md": "docs/reports/redundancy_scan_${DATE}.md",
      "report_json": "docs/reports/redundancy_scan_${DATE}.json",
      "log_path": "output/logs/redundancy_scan.log"
    },
    "file_reference_format": "path:line"
  },

  "analysis": {
    "duplicates": {
      "exact": {
        "enabled": true,
        "min_consecutive_lines": 5,
        "normalization": ["strip_whitespace", "drop_blank_lines", "drop_comments"],
        "hash_algorithm": "sha1"
      },
      "near": {
        "enabled": true,
        "shingle_lines": 5,
        "similarity": "jaccard",
        "threshold": 0.85,
        "normalization": ["strip_whitespace", "drop_blank_lines", "inline_spaces_to_single"]
      }
    },
    "dead_code": {
      "enabled": true,
      "method": "python_ast_graph",
      "detect": [
        "unused_functions",
        "unused_classes",
        "unused_module_level_consts",
        "unreachable_code_blocks"
      ],
      "optional_tools": [
        { "name": "vulture", "use_if_available": true },
        { "name": "pylint R0801", "use_if_available": true }
      ]
    },
    "imports": {
      "enabled": true,
      "detect": ["unused_imports", "duplicate_imports"],
      "optional_tools": [
        { "name": "flake8 F401", "use_if_available": true }
      ]
    },
    "repo_specific_rules": [
      {
        "id": "registry-unused-factory",
        "description": "Flag event/doc extractor factory functions that exist but are not referenced by the dynamic registries or tests.",
        "patterns": [
          "src/core/extractor_factory.py",
          "src/core/event_extractor_catalog.py",
          "src/core/document_extractor_catalog.py",
          "tests/test_event_extractor_registry.py"
        ]
      },
      {
        "id": "catalog-disabled-unreferenced",
        "description": "List catalog entries with enabled=false that have no references in UI/CLI/tests (informational).",
        "patterns": [
          "src/core/event_extractor_catalog.py",
          "src/core/document_extractor_catalog.py",
          "app.py",
          "scripts/**/*.py",
          "tests/**/*.py"
        ]
      }
    ]
  },

  "execution": {
    "steps": [
      {
        "id": "S1",
        "name": "Index Files",
        "action": "Enumerate files by scope, apply size filters, store line maps."
      },
      {
        "id": "S2",
        "name": "Exact Duplicate Detection",
        "action": "Normalize and hash N-line windows; report identical hashes across different files/locations."
      },
      {
        "id": "S3",
        "name": "Near-Duplicate Detection",
        "action": "Compute k-line shingles and Jaccard similarity; report pairs/groups over threshold."
      },
      {
        "id": "S4",
        "name": "Dead Code Analysis",
        "action": "Parse AST to collect defs/refs; mark unused definitions. Optionally run external tools if available."
      },
      {
        "id": "S5",
        "name": "Import Hygiene",
        "action": "Detect unused/duplicate imports per file."
      },
      {
        "id": "S6",
        "name": "Repo-Specific Rules",
        "action": "Apply registry/catalog heuristics to spot unreferenced factories and disabled entries."
      },
      {
        "id": "S7",
        "name": "Report Generation",
        "action": "Write JSON + Markdown reports with sections and path:line references."
      }
    ],
    "tooling": {
      "preferred_search": "rg",
      "max_read_chunk_lines": 250,
      "python_ast": true,
      "hashlib": "sha1"
    },
    "timeouts": {
      "overall_seconds": 300,
      "per_step_seconds": 90
    }
  },

  "report_format": {
    "sections": [
      "summary",
      "exact_duplicates",
      "near_duplicates",
      "unused_definitions",
      "unused_imports",
      "registry_findings",
      "suggested_refactors"
    ],
    "summary_fields": [
      "files_scanned",
      "exact_duplicate_groups",
      "near_duplicate_groups",
      "unused_defs_count",
      "unused_imports_count",
      "notes"
    ],
    "path_reference_style": "path:line"
  },

  "constraints": {
    "do_not": [
      "Modify repository files",
      "Execute repository code",
      "Use network calls"
    ],
    "must": [
      "Respect file limits and chunked reads",
      "Report zero-findings explicitly as 'none'",
      "Include at least 3 concrete examples when findings exist"
    ]
  },

  "validation": {
    "acceptance_criteria": [
      "Both report files exist at configured paths",
      "Report includes counts for each section",
      "File references use path:line format"
    ],
    "post_checks": [
      "Confirm no writes outside docs/reports/ and output/logs/",
      "Confirm scan respected include/exclude paths"
    ]
  },

  "metadata": {
    "created_at": "${NOW}",
    "created_by": "agent",
    "status": "draft",
    "notes": [
      "Set DATE as YYYY-MM-DD and NOW as ISO timestamp at runtime.",
      "Optional external tools (vulture/flake8/pylint) run only if preinstalled."
    ]
  }
}

