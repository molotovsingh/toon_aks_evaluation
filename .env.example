# ===============================================================================
# Environment Variables for Legal Event Extraction
# ===============================================================================
# Copy this file to .env and add your API keys
#
# Supported providers: LangExtract (Gemini), OpenRouter, OpenCode Zen, OpenAI, Anthropic
# See docs/reference/configuration.md for model comparisons and pricing
# ===============================================================================

# ====================
# Event Extraction Providers
# ====================
# Based on 2025-10-03 testing:
#
# DIGITAL PDFs (docs/benchmarks/2025-10-03-manual-comparison.md):
# - OpenRouter (GPT-4o-mini): ⭐ Best overall (8/10 quality, ~$0.015/doc, 14s)
# - Anthropic (Claude 3 Haiku): Speed/Cost (7/10 quality, $0.003/doc, 4.4s)
# - OpenAI (GPT-4o-mini): Quality (8/10 quality, $0.03/doc, 18s)
# - LangExtract (Gemini 2.0 Flash): Completeness (6/10 quality, ~$0.01/doc, 36s)
#
# SCANNED PDFs (docs/benchmarks/2025-10-03-ocr-comparison.md):
# - Anthropic (Claude 3 Haiku): ⭐ OCR Champion (10/10 quality, $0.0005/doc, 2s)
# - OpenAI (GPT-4o-mini): Maximum detail (10/10 quality, $0.0039/doc, 6s)
# - OpenRouter (GPT-4o-mini): Consistent (10/10 quality, ~$0.008/doc, 8s)
# - LangExtract (Gemini 2.0 Flash): Comprehensive (7/10 quality, ~$0.002/doc, 4s)
#
# KEY FINDING: ✅ OCR does NOT degrade extraction quality - Docling OCR is production-ready!

# OpenRouter (Unified Multi-Provider API) ⭐ RECOMMENDED DEFAULT
# OPENROUTER_API_KEY=your_openrouter_api_key_here
# OPENROUTER_MODEL=openai/gpt-4o-mini
#
# Curated models (Oct 2025 testing - 10/10, 9/10, or 7/10 quality):
# - openai/gpt-4o-mini: $0.15/M, 128K context (⭐ recommended starting point, 9/10)
# - deepseek/deepseek-r1-distill-llama-70b: $0.03/M, 128K (50x cheaper, 10/10 quality!)
# - qwen/qwq-32b: $0.115/M, 128K (ultra-cheap, 7/10, ⚠️ may miss events on complex docs)
# - anthropic/claude-3-haiku: $0.25/M, 200K (fastest: 4.4s, long docs, 10/10)
# - anthropic/claude-3-5-sonnet: $3/M, 200K (premium quality, 10/10, 50+ page contracts)
# - meta-llama/llama-3.3-70b-instruct: $0.60/M, 128K (open source option, 10/10)
#
# ⚠️ Excluded models (failed Oct 2025 JSON tests): All Gemini variants, Cohere, Perplexity
#
# ⚠️ Additional exclusions (Oct 5 OSS model testing - after adapter fix):
# - openai/gpt-oss-20b, openai/gpt-oss-120b: Return empty responses even with prompt-based JSON (1/10)
# - mistralai/mistral-small-24b-instruct-2501: Weak real-doc extraction (7/10, 1 event vs ≥3 expected)
#
# ✅ Oct 5 adapter fix: Added conditional JSON mode support (prompt-based fallback)
# - Qwen QwQ 32B now works (7/10 quality, was failing before)
# - OpenRouter adapter now tries native JSON mode first, falls back to prompt-based
# - Automatically strips markdown wrappers from responses
#
# Key finding: Native JSON mode (response_format) is NOT mandatory - many models work via prompts.
# Testing with real legal documents remains essential for curation.

# Anthropic Direct API (Speed/Cost Champion)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL=claude-3-haiku-20240307

# OpenAI Direct API (Quality Champion)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4o-mini

# LangExtract (Google Gemini) - Completeness Champion
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_API_KEY=your_google_api_key_here

# OpenCode Zen (Legal AI Gateway) - ⚠️ Currently unstable
# OPENCODEZEN_API_KEY=your_opencode_zen_api_key_here
# OPENCODEZEN_MODEL=grok-code

# ====================
# DeepSeek Direct API (✅ Available - Week 3)
# ====================
# Pricing: $0.27/M input, $1.10/M output
# Signup: https://platform.deepseek.com (instant, no approval)
# DEEPSEEK_API_KEY=your_deepseek_api_key_here
# DEEPSEEK_MODEL=deepseek-chat
# DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# ====================
# 3-Judge Panel System (Phase 4 - Advanced Evaluation)
# ====================
# Premium reasoning models for robust legal event extraction evaluation
# Uses GPT-5, Claude Opus 4.1, and Gemini 2.5 Pro with consensus mechanism
#
# Requirements (all 3 API keys):
# - OPENAI_API_KEY (GPT-5 with reasoning_effort="high")
# - ANTHROPIC_API_KEY (Claude Opus 4.1 with extended thinking)
# - GEMINI_API_KEY (Gemini 2.5 Pro with built-in thinking)
#
# Cost: ~$0.25 per document (vs $0.01 single judge)
# Validation: ✅ Matches Phase 2 manual evaluation
# Inter-judge agreement: 0.974 (exceptional)
# Confidence level: HIGH
#
# Run validation: uv run python scripts/validate_judge_panel.py
#
# All keys already configured above ✅

# ====================
# Future Providers (Phase 1 - Week 4)
# ====================

# Moonshot AI (Kimi K2) - HIGH RISK: Chinese API, phone verification, VPN
# MOONSHOT_API_KEY=your_moonshot_api_key_here
# MOONSHOT_MODEL=moonshot-v1-128k

# Zhipu AI (ChatGLM) - HIGH RISK: Chinese API, approval process
# ZHIPU_API_KEY=your_zhipu_api_key_here
# ZHIPU_MODEL=glm-4

# ====================
# Optional Configuration
# ====================

# File paths (defaults work for most users)
# INPUT_DIR=input
# OUTPUT_DIR=output

# Performance timing (captures Docling + LLM extraction duration)
ENABLE_PERFORMANCE_TIMING=true

# ====================
# Docling PDF Processing Configuration
# ====================
# ⚡ Performance optimization: Disable OCR for digital PDFs (16x speedup)
# Benchmark results (2025-10-02): 35s → 2s per medium document
# Use DOCLING_DO_OCR=true only for scanned documents requiring OCR

# OCR Configuration (⭐ recommended: false for digital PDFs)
DOCLING_DO_OCR=false

# Auto-detect scanned PDFs and enable OCR automatically (⭐ NEW feature)
# When enabled: Checks PDF text layer, auto-enables OCR only for scanned docs
# Result: Digital PDFs stay fast (2s), scanned PDFs get OCR (22s with Tesseract)
DOCLING_AUTO_OCR_DETECTION=true

# OCR Engine Selection (⭐ NEW - 2025-10-03 benchmark: docs/benchmarks/2025-10-03-ocr-engine-war.md)
# ⭐ RECOMMENDED: Tesseract (3x faster than EasyOCR, 31% more text, production-ready)
# Options: tesseract (default), easyocr, ocrmac (macOS only), rapidocr (fast but low quality)
# DOCLING_OCR_ENGINE=tesseract
#
# Tesseract Language Data Path (REQUIRED when using tesseract engine)
# macOS (Homebrew): export TESSDATA_PREFIX=/usr/local/opt/tesseract/share/tessdata
# Linux (apt): export TESSDATA_PREFIX=/usr/share/tesseract-ocr/4.00/tessdata
# Windows: export TESSDATA_PREFIX=C:\Program Files\Tesseract-OCR\tessdata
#
# Install Tesseract:
# macOS: brew install tesseract
# Linux: sudo apt install tesseract-ocr libtesseract-dev
# Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki

# Table Processing (keep enabled for legal documents)
DOCLING_DO_TABLE_STRUCTURE=true
DOCLING_TABLE_MODE=FAST
DOCLING_DO_CELL_MATCHING=true

# Advanced Configuration (defaults usually work)
# DOCLING_BACKEND=default
# DOCLING_ACCELERATOR_DEVICE=cpu
# DOCLING_ACCELERATOR_THREADS=4
# DOCLING_DOCUMENT_TIMEOUT=300

# For detailed provider comparison, pricing, and setup guides, see:
# docs/reference/configuration.md

# ====================
# OCR Engine War (benchmark script) settings
# ====================
# Rasterization and page budget for scripts/ocr_engine_war.py
# OCR_ENGINE_DPI=300
# OCR_ENGINE_PAGE_LIMIT=2

# Tesseract runtime (used by tesserocr)
# TESSERACT_LANGS=eng
# TESSERACT_OEM=1     # LSTM-only
# TESSERACT_PSM=6     # Assume a block of text
# TESSDATA_PREFIX=/usr/share/tesseract-ocr/4.00/tessdata

# PaddleOCR runtime
# PADDLEOCR_LANG=en
# PADDLEOCR_USE_ANGLE_CLS=true
